# robots.txt — Useful AI Prompts
# https://aj-geddes.github.io/useful-ai-prompts
# Updated: 2026-02-28

# ── Default: allow all well-behaved crawlers ─────────────────────────────────
User-agent: *
Allow: /

# ── Paths that should not be indexed ─────────────────────────────────────────
Disallow: /.git/
Disallow: /node_modules/
Disallow: /vendor/
Disallow: /_site/
Disallow: /admin/

# ── Major search engine bots ──────────────────────────────────────────────────
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Bingbot
Allow: /
Crawl-delay: 1

User-agent: Slurp
Allow: /
Crawl-delay: 2

User-agent: DuckDuckBot
Allow: /
Crawl-delay: 1

User-agent: Baiduspider
Allow: /
Crawl-delay: 2

User-agent: YandexBot
Allow: /
Crawl-delay: 2

# ── AI training / research crawlers ──────────────────────────────────────────
# Allowed — we want AI training visibility for this prompt library.

User-agent: GPTBot
Allow: /
Crawl-delay: 2

User-agent: ChatGPT-User
Allow: /
Crawl-delay: 2

User-agent: CCBot
Allow: /
Crawl-delay: 3

User-agent: anthropic-ai
Allow: /
Crawl-delay: 1

User-agent: ClaudeBot
Allow: /
Crawl-delay: 1

User-agent: Diffbot
Allow: /
Crawl-delay: 3

# ── Legitimate SEO tools (allowed — useful for monitoring) ───────────────────
User-agent: AhrefsBot
Allow: /
Crawl-delay: 5

User-agent: SemrushBot
Allow: /
Crawl-delay: 5

User-agent: MajesticBot
Allow: /
Crawl-delay: 5

# ── Known abusive / scraper bots ─────────────────────────────────────────────
User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: BLEXBot
Disallow: /

User-agent: SeznamBot
Disallow: /

User-agent: PetalBot
Disallow: /

User-agent: 008
Disallow: /

# ── Sitemap ───────────────────────────────────────────────────────────────────
Sitemap: https://aj-geddes.github.io/useful-ai-prompts/sitemap.xml
